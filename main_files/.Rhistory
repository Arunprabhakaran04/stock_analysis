)
# Plot
ggplot(results_df, aes(x = Date)) +
geom_line(aes(y = Actual, color = "Actual"), size = 1.1) +
geom_line(aes(y = Predicted, color = "Predicted"), size = 1.1, linetype = "dashed") +
labs(title = "Prophet Forecast vs Actual Close Prices",
y = "Close Price", color = "Legend") +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red")) +
theme_minimal()
prophet_df <- data.frame(ds = data$Date, y = log(data$Close))  # log scale
# ----- 2. Split the data -----
test_size <- 50
train_df <- prophet_df[1:(nrow(prophet_df) - test_size), ]
test_df <- prophet_df[(nrow(prophet_df) - test_size + 1):nrow(prophet_df), ]
# ----- 3. Setup and tune Prophet model -----
m <- prophet(
train_df,
changepoint.prior.scale = 0.05,    # lower = smoother trend
seasonality.mode = 'multiplicative', # good for % changes
yearly.seasonality = TRUE,
weekly.seasonality = TRUE,
daily.seasonality = FALSE
)
# Optional: add custom seasonality (e.g., monthly)
m <- add_seasonality(m, name = 'monthly', period = 30.5, fourier.order = 5)
prophet_df <- data.frame(ds = data$Date, y = log(data$Close))
# ----- 2. Train/Test Split -----
test_size <- 50
train_df <- prophet_df[1:(nrow(prophet_df) - test_size), ]
test_df <- prophet_df[(nrow(prophet_df) - test_size + 1):nrow(prophet_df), ]
# ----- 3. Initialize Prophet model (before fitting!) -----
m <- prophet(
changepoint.prior.scale = 0.05,         # smoother trend
seasonality.mode = 'multiplicative',    # good for stock-like data
yearly.seasonality = TRUE,
weekly.seasonality = TRUE,
daily.seasonality = FALSE
)
# ðŸ” Add custom monthly seasonality BEFORE fitting
m <- add_seasonality(m, name = 'monthly', period = 30.5, fourier.order = 5)
# ----- 4. Fit the model -----
m <- fit.prophet(m, train_df)
# ----- 5. Forecast into the future -----
future <- make_future_dataframe(m, periods = test_size)
forecast <- predict(m, future)
# ----- 6. Plot forecast and components -----
plot(m, forecast)
prophet_plot_components(m, forecast)
# ----- 7. Evaluate RMSE (back to original scale) -----
predicted_log <- tail(forecast$yhat, test_size)
actual_log <- test_df$y
# Inverse log to get real Close prices
predicted <- exp(predicted_log)
actual <- exp(actual_log)
rmse <- sqrt(mean((predicted - actual)^2))
cat("Optimized Prophet RMSE:", rmse, "\n")
# ----- 8. Custom Visual: Actual vs Predicted -----
results_df <- data.frame(
Date = test_df$ds,
Actual = actual,
Predicted = predicted
)
ggplot(results_df, aes(x = Date)) +
geom_line(aes(y = Actual, color = "Actual"), size = 1.2) +
geom_line(aes(y = Predicted, color = "Predicted"), size = 1.2, linetype = "dashed") +
labs(title = "Optimized Prophet Forecast vs Actual Close Prices",
y = "Close Price", color = "Legend") +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red")) +
theme_minimal()
prophet_df <- data.frame(ds = data$Date, y = data$Close)
# Define train/test split
test_size <- 50
train_df <- prophet_df[1:(nrow(prophet_df) - test_size), ]
test_df <- prophet_df[(nrow(prophet_df) - test_size + 1):nrow(prophet_df), ]
# ----- 2. Fit Prophet Model -----
m <- prophet(train_df)
# ----- 3. Make Future Dataframe & Forecast -----
future <- make_future_dataframe(m, periods = test_size)
forecast <- predict(m, future)
# ----- 4. Plot Forecast -----
plot(m, forecast)
prophet_plot_components(m, forecast)
# ----- 5. Evaluate Model Performance -----
# Extract predicted and actual values for test period
predicted <- tail(forecast$yhat, test_size)
actual <- test_df$y
# Calculate RMSE
rmse <- sqrt(mean((predicted - actual)^2))
cat("Prophet RMSE:", rmse, "\n")
# ----- 6. Visualize Actual vs Predicted -----
# Combine into one dataframe for ggplot
results_df <- data.frame(
Date = test_df$ds,
Actual = actual,
Predicted = predicted
)
# Plot
ggplot(results_df, aes(x = Date)) +
geom_line(aes(y = Actual, color = "Actual"), size = 1.1) +
geom_line(aes(y = Predicted, color = "Predicted"), size = 1.1, linetype = "dashed") +
labs(title = "Prophet Forecast vs Actual Close Prices",
y = "Close Price", color = "Legend") +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red")) +
theme_minimal()
X_matrix <- as.matrix(X)
X_train <- X_matrix[1:(n-test_size), ]
X_test <- X_matrix[(n-test_size+1):n, ]
# Fit SARIMAX model
sarimax_model <- auto.arima(y_train, xreg = X_train, seasonal = TRUE)
# Forecast with exogenous variables
sarimax_forecast <- forecast(sarimax_model, xreg = X_test, h = test_size)
plot(sarimax_forecast)
print(sarimax_forecast$mean)
sarimax_rmse <- sqrt(mean((sarimax_forecast$mean - y_test)^2))
cat("SARIMAX RMSE:", sarimax_rmse, "\n")
n <- nrow(data)
test_size <- 50
X_train <- X[1:(n-test_size), ]
y_train <- y[1:(n-test_size)]
X_test <- X[(n-test_size+1):n, ]
y_test <- y[(n-test_size+1):n]
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
library(xgboost)
library(caret)
library(Metrics)
library(ggplot2)
y <- data$Close
X <- data[, !colnames(data) %in% c("Close", "Date")]
n <- nrow(data)
test_size <- 50
X_train <- X[1:(n-test_size), ]
y_train <- y[1:(n-test_size)]
X_test <- X[(n-test_size+1):n, ]
y_test <- y[(n-test_size+1):n]
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)
params <- list(
objective = "reg:squarederror",
eval_metric = "rmse"
)
epochs <- 100
model <- xgb.train(
params = params,
data = dtrain,
nrounds = epochs
)
y_pred <- predict(model, dtest)
print(y_pred)
rmse_value <- rmse(y_test, y_pred)
print(paste("Root Mean Squared Error:", round(rmse_value, 4)))
mae <- mean(abs(y_test - y_pred))
mape <- mean(abs((y_test - y_pred) / y_test)) * 100
cat("MAE:", mae, "\n")
cat("MAPE (%):", mape, "\n")
rmse_value <- rmse(y_test, y_pred)
print(paste("Root Mean Squared Error:", round(rmse_value, 4)))
#Light BGM training -
#install.packages("lightgbm") # Skip this if already installed
library(lightgbm)
library(Metrics)
n <- nrow(data)
test_size <- 50
X_train <- as.matrix(X[1:(n - test_size), ])
y_train <- y[1:(n - test_size)]
X_test <- as.matrix(X[(n - test_size + 1):n, ])
y_test <- y[(n - test_size + 1):n]
dtrain <- lgb.Dataset(data = X_train, label = y_train)
params <- list(
objective = "regression",
metric = "rmse",
learning_rate = 0.05,
num_leaves = 31,
verbosity = -1
)
model <- lgb.train(
params = params,
data = dtrain,
nrounds = 100
)
y_pred <- predict(model, X_test)
print(y_pred)
rmse_val <- rmse(y_test, y_pred)
print(paste("LightGBM RMSE:", round(rmse_val, 4)))
mae <- mean(abs(y_test - y_pred))
mape <- mean(abs((y_test - y_pred) / y_test)) * 100
cat("MAE:", mae, "\n")
cat("MAPE (%):", mape, "\n")
X_matrix <- as.matrix(X)
# Train/test split
X_train <- X_matrix[1:(n - test_size), ]
X_test <- X_matrix[(n - test_size + 1):n, ]
y_train <- y[1:(n - test_size)]
y_test <- y[(n - test_size + 1):n]
# Fit SARIMAX model with exogenous regressors
sarimax_model <- auto.arima(y_train, xreg = X_train, seasonal = TRUE)
# Forecast with future xreg
sarimax_forecast <- forecast(sarimax_model, xreg = X_test, h = test_size)
# Plot forecast
plot(sarimax_forecast, main = "SARIMAX Forecast")
# Extract predictions
y_pred <- as.numeric(sarimax_forecast$mean)
# Evaluation metrics
sarimax_rmse <- sqrt(mean((y_pred - y_test)^2))
sarimax_mae <- mean(abs(y_pred - y_test))
sarimax_mape <- mean(abs((y_pred - y_test) / y_test)) * 100
# Print results
cat("ðŸ“Š SARIMAX Evaluation Metrics:\n")
cat("RMSE :", sarimax_rmse, "\n")
cat("MAE  :", sarimax_mae, "\n")
cat("MAPE (%):", sarimax_mape, "\n")
# Visualization: Actual vs Predicted
results_df <- data.frame(
Index = 1:test_size,
Actual = y_test,
Predicted = y_pred
)
ggplot(results_df, aes(x = Index)) +
geom_line(aes(y = Actual, color = "Actual"), size = 1.2) +
geom_line(aes(y = Predicted, color = "Predicted"), size = 1.2, linetype = "dashed") +
labs(title = "SARIMAX Forecast vs Actual Close Prices",
y = "Close Price", color = "Legend") +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red")) +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(quantmod)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(zoo)
library(corrplot)
library(gridExtra)
#stock data from yahoo API -
fetch_stock_data <- function(stock) {
start_date <- Sys.Date() - (5 * 365)
df <- getSymbols(stock, src = "yahoo", from = start_date, auto.assign = FALSE)
df <- data.frame(Date = index(df), coredata(df))
return(df)
}
#data structuring
structure_data <- function(df, stock) {
close_col <- grep("Close", colnames(df), value = TRUE)
df <- df %>% rename(Close = all_of(close_col))
df$Date <- as.Date(df$Date)
return(df)
}
data_discovery_description <- function(df, stock) {
print("Initial Data Examination")
print(dim(df))
print(str(df))
print(colSums(is.na(df)))
print(summary(df))
}
data_discovery_visualization <- function(df, stock) {
p1 <- ggplot(df, aes(x = Close)) +
geom_histogram(fill = "blue", bins = 30, alpha = 0.7) +
labs(title = "Distribution of Closing Prices",
x = "Closing Price",
y = "Frequency") +
theme_minimal()
p2 <- ggplot(df, aes(y = Close)) +
geom_boxplot(fill = "red", alpha = 0.6) +
labs(title = "Boxplot of Closing Prices",
y = "Closing Price") +
theme_minimal()
p3 <- ggplot(df, aes(x = Date, y = Close)) +
geom_line(color = "blue", size = 1) +
labs(title = paste("Stock Price Trend for", stock),
x = "Date",
y = "Closing Price") +
theme_minimal()
grid.arrange(p1, p2, p3, ncol = 2)
}
clean_data <- function(df, stock) {
print("Starting Data Cleaning...")
if (nrow(df) == 0) {
stop("Error: The dataset is empty. Check if the stock symbol is correct.")
}
div_col <- grep("Dividends", colnames(df), value = TRUE)
split_col <- grep("Stock.Splits", colnames(df), value = TRUE)
if (length(div_col) > 0) {
df <- select(df, -all_of(div_col))
print("Removed 'Dividends' column.")
}
if (length(split_col) > 0) {
df <- select(df, -all_of(split_col))
print("Removed 'Stock Splits' column.")
}
if ("Date" %in% colnames(df)) {
df$Date <- as.Date(df$Date)
print("Converted 'Date' column to Date format.")
}
num_cols <- colnames(df)[sapply(df, is.character)]
df[num_cols] <- lapply(df[num_cols], function(x) as.numeric(as.character(x)))
print("Converted numeric columns to numeric data type.")
missing_summary <- colSums(is.na(df))
print("Missing Values Before Cleaning:")
print(missing_summary)
if (sum(missing_summary) > 0) {
for (col in colnames(df)) {
if (is.numeric(df[[col]]) & sum(is.na(df[[col]])) > 0) {
df[[col]][is.na(df[[col]])] <- median(df[[col]], na.rm = TRUE)
print(paste("Filled missing values in", col, "with median."))
}
}
}
df <- df %>% distinct()
print("Removed duplicate rows.")
print("Data Cleaning Completed. Final Summary:")
print(colSums(is.na(df)))
print(dim(df))
return(df)
}
feature_engineering <- function(df) {
df <- df %>%
mutate(
tomorrow = lead(Close, 1),
yesterday = lag(Close, 1),
daily_return = (Close - yesterday) / yesterday * 100,
SMA_7 = rollmean(Close, k = 7, fill = NA, align = "right"),
SMA_30 = rollmean(Close, k = 30, fill = NA, align = "right"),
volatility_10 = rollapply(daily_return, width = 10, FUN = sd, fill = NA, align = "right")
)
df <- na.omit(df)
return(df)
}
validate_data <- function(df) {
print("Step 6: Data Validation")
if (nrow(df) == 0) {
stop("Error: The dataset is empty. Check if the stock symbol is correct or if data was fetched properly.")
}
required_cols <- c("Date", "Close", "daily_return", "SMA_7", "SMA_30", "volatility_10")
missing_cols <- setdiff(required_cols, colnames(df))
if (length(missing_cols) > 0) {
stop(paste("Error: The following required columns are missing:", paste(missing_cols, collapse=", ")))
}
missing_summary <- colSums(is.na(df))
print("Missing Values Summary:")
print(missing_summary)
if (sum(missing_summary) > 0) {
warning("Warning: Missing values detected. Consider handling them before further analysis.")
}
if (!inherits(df$Date, "Date")) {
warning("Warning: 'Date' column is not in Date format. Converting now.")
df$Date <- as.Date(df$Date)
}
num_cols <- c("Close", "daily_return", "SMA_7", "SMA_30", "volatility_10")
for (col in num_cols) {
if (!is.numeric(df[[col]])) {
warning(paste("Warning:", col, "is not numeric. Converting now."))
df[[col]] <- as.numeric(as.character(df[[col]]))
}
}
q1 <- quantile(df$Close, 0.25, na.rm = TRUE)
q3 <- quantile(df$Close, 0.75, na.rm = TRUE)
iqr_value <- q3 - q1
lower_bound <- q1 - (1.5 * iqr_value)
upper_bound <- q3 + (1.5 * iqr_value)
outliers <- df$Close[df$Close < lower_bound | df$Close > upper_bound]
if (length(outliers) > 0) {
warning(paste("Warning: Detected", length(outliers), "outliers in Closing Prices."))
}
duplicate_rows <- sum(duplicated(df))
if (duplicate_rows > 0) {
warning(paste("Warning: Dataset contains", duplicate_rows, "duplicate rows. Consider removing them."))
}
print("Final Validation Summary:")
print(dim(df))
print(colSums(is.na(df)))
print(summary(df))
}
visualize_data <- function(df, stock) {
p1<-ggplot(df, aes(x = Date, y = Close)) +
geom_line(color = "blue", size = 1) +
labs(title = paste("Stock Price Trend for", stock),
x = "Date",
y = "Closing Price") +
theme_minimal()
p2<-ggplot(df, aes(x = Close)) +
geom_histogram(fill = "blue", bins = 30, alpha = 0.7) +
labs(title = "Distribution of Closing Prices",
x = "Closing Price",
y = "Frequency") +
theme_minimal()
p3<-ggplot(df, aes(y = daily_return)) +
geom_boxplot(fill = "red", alpha = 0.6) +
labs(title = "Daily Return Distribution",
y = "Daily Return (%)") +
theme_minimal()
p4<-ggplot(df, aes(x = Date)) +
geom_line(aes(y = Close), color = "black", size = 1, alpha = 0.6) +
geom_line(aes(y = SMA_7), color = "blue", size = 1, linetype = "dashed") +
geom_line(aes(y = SMA_30), color = "red", size = 1, linetype = "dashed") +
labs(title = paste("Stock Price with Moving Averages for", stock),
x = "Date",
y = "Price") +
theme_minimal()
grid.arrange(p1, p2, p3, p4, ncol = 2)
numeric_df <- df %>% select(-Date)
cor_matrix <- cor(numeric_df, use = "complete.obs")
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 0.8, tl.col = "black", number.cex = 0.7)
}
publish_data <- function(df, stock) {
file_name <- paste0("D:\\R\\stock_sentiment_analysis\\stock_data_preprocessed_", stock, ".csv")
write.csv(df, file_name, row.names = FALSE)
print("Preprocessed file saved.")
report_content <- paste0("
# Stock Market Data Wrangling Report
## Dataset Description
- The dataset contains 5 years of historical stock prices for ", stock, ", collected from Yahoo Finance.
- Columns include Open, High, Low, Close, Volume, and derived features like daily returns.
- The dataset is structured as a time series, making it suitable for financial modeling and forecasting.
- Data is collected at daily intervals, capturing price movements and trading activity over time.
## Additional Features
- **7-day & 30-day Moving Averages (SMA)**: Provides insights into short-term and long-term price trends.
- **Rolling Volatility (10-day standard deviation)**: Measures price fluctuations, helping assess market risk.
- **Daily Returns Distribution Analysis**: Helps evaluate stock performance and detect anomalies.
- **Exponential Moving Averages (EMA)**: Adds more weight to recent prices for improved trend detection.
- **Relative Strength Index (RSI)**: Identifies overbought or oversold conditions for trading decisions.
- **Bollinger Bands**: Defines price volatility boundaries to detect breakout trends.
- **Moving Average Convergence Divergence (MACD)**: Helps identify momentum shifts in stock price movements.
- **Average True Range (ATR)**: Measures market volatility to assist in risk assessment.
## Potential Use Cases
- **Stock Market Trend Analysis**: Investors can use moving averages and MACD to identify bullish or bearish trends.
- **Risk Assessment and Volatility Analysis**: Volatility measures and ATR help investors manage portfolio risk.
- **Algorithmic Trading Strategies**: The dataset can be leveraged for developing automated trading signals.
- **Stock Price Prediction**: Machine learning models can be trained using historical price data for predictive analytics.
- **Market Sentiment and Behavioral Finance Research**: Analyzing how price fluctuations correlate with external financial events and news.
- **Portfolio Optimization**: Helps investors compare stocks based on risk-adjusted returns.
## Final Processed Dataset
The processed dataset is saved as ", file_name, ".
")
file_path <- paste0("D:\\R\\stock_sentiment_analysis\\stock_data_report_", stock, ".txt")
write(report_content, file_path)
print("Processed data and report have been saved successfully.")
}
stock <- readline(prompt="Enter a stock symbol (e.g., AAPL, TSLA, MSFT): ")
#stock<-"MSFT"
df <- fetch_stock_data(stock)
print(head(df))
df <- structure_data(df, stock)
#here we change the name of the attribute close for better mining of information.
print(head(df))
data_discovery_description(df, stock)
data_discovery_visualization(df, stock)
df <- clean_data(df, stock)
print(head(df))
df <- feature_engineering(df)
print(head(df))
print(str(df))
validate_data(df)
validate_vis <- function(df){
# Scatter Plot for Anomly detection
ggplot(df, aes(x = Date, y = daily_return)) +
geom_point(color = "green", alpha = 0.5) +
labs(title = "Scatter Plot of Daily Returns (Anomaly Detection)",
x = "Date",
y = "Daily Return (%)") +
theme_minimal()
}
validate_vis(df)
visualize_data(df, stock)
y <- data$Close
X <- data[, !colnames(data) %in% c("Close", "Date")]
n <- nrow(data)
test_size <- 50
X_train <- X[1:(n-test_size), ]
y_train <- y[1:(n-test_size)]
X_test <- X[(n-test_size+1):n, ]
y_test <- y[(n-test_size+1):n]
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)
params <- list(
objective = "reg:squarederror",
eval_metric = "rmse"
)
epochs <- 100
model <- xgb.train(
params = params,
data = dtrain,
nrounds = epochs
)
y_pred <- predict(model, dtest)
print(y_pred)
str(data)
mae <- mean(abs(y_test - y_pred))
mape <- mean(abs((y_test - y_pred) / y_test)) * 100
cat("MAE:", mae, "\n")
cat("MAPE (%):", mape, "\n")
rmse_value <- rmse(y_test, y_pred)
print(paste("Root Mean Squared Error:", round(rmse_value, 4)))
plot_data <- data.frame(
Date = tail(dates, test_size),
Actual = y_test,
Predicted = y_pred
)
plot_data_long <- tidyr::pivot_longer(
plot_data,
cols = c("Actual", "Predicted"),
names_to = "Type",
values_to = "Price"
)
ggplot(plot_data_long, aes(x = as.Date(Date), y = Price, color = Type, group = Type)) +
geom_line() +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red")) +
labs(
title = "Predicted vs. Actual Stock Prices",
x = "Date",
y = "Close Price"
) +
theme_minimal() +
theme(legend.position = "bottom")
